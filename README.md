# Semantic Vault â€” AI-Powered Semantic Search for Your Markdown Notes

> ğŸ” Ask questions to your knowledge base with OpenAI, Gemini, or Local LLMs  
> ğŸ—‚ï¸ Tag Generator Included â€” Perfect for Obsidian Vaults

---

## ğŸ“– Overview

**Semantic Vault** brings semantic search to your Markdown notes, optimized for Obsidian users but adaptable to any `.md` folder. Ask natural language questions and get relevant answers based on your notes.

Includes an AI-powered tag generator to enrich your notes automatically â€” great for organizing Obsidian vaults.

> ![alt text](./images/demo1.png)

> ![alt text](./images/demo2.png)

---

## ğŸš€ Features

âœ… AI-Powered Semantic Search (Chat interface)  
âœ… **Beautiful Web Interface** â€” Modern browser-based UI  
âœ… Supports OpenAI, Gemini, and Ollama Local LLMs  
âœ… Markdown & Obsidian Vault Friendly  
âœ… AI Tag Generation Script â€” YAML Compatible  
âœ… Easy Setup with `requirements.txt`

---

## ğŸ› ï¸ Requirements

- Python 3.9+
- Dependencies (use the provided `requirements.txt`)

```bash
pip3 install -r requirements.txt
```

- Optional:
  - OpenAI API Key â†’ [Get one](https://platform.openai.com/account/api-keys)
  - Google Gemini API Key â†’ [Get one](https://aistudio.google.com/app/apikey)
  - Ollama for local LLMs â†’ [See Ollama Setup](#-ollama-local-llm-optional)

---

## ğŸ“‚ Project Structure

```
semantic-vault/
â”œâ”€â”€ semanticVault.py      # Main Semantic Search Script
â”œâ”€â”€ auto_tag_generation.py # AI Tag Generator for Markdown Notes
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Web UI template
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env                  # API keys configuration (create this)
â””â”€â”€ README.md
```

---

## ğŸ”§ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/renantmagalhaes/semantic-vault.git
cd semantic-vault
```

### 2. Install Dependencies

```bash
pip3 install -r requirements.txt
```

### 3. Configure Environment

Create a `.env` file:

```ini
OPENAI_API_KEY="your_openai_key_here"
GEMINI_API_KEY="your_openai_key_here"
```

Only required if using OpenAI or Gemini models.

---

## ğŸ’¡ Semantic Search Usage

### 1. Set Your Vault Path

Edit `semanticVault.py`:

```python
VAULT_PATH = "/path/to/your/obsidian/vault"
```

### 2. Choose Your AI Model

In `semanticVault.py`:

```python
USE_MODEL = "openai"  # Options: "openai", "gemini", "ollama"
```

### 3. Run the Search Tool

**CLI Mode (Command Line):**

```bash
python3 ./semanticVault.py
```

Ask your question in the terminal, get AI-driven answers based on your notes.

**Web Interface Mode (Recommended):**

```bash
python3 ./semanticVault.py --web
```

Then open your browser to `http://localhost:5000` to access the beautiful web interface!

The web UI features:

- ğŸ¨ Modern, responsive design with gradient themes
- ğŸ’¬ Chat-style interface for natural conversations
- ğŸ“Š Real-time statistics (note count, model type)
- âš¡ Smooth animations and loading indicators
- ğŸ“± Mobile-friendly responsive layout

---

## ğŸ·ï¸ AI Tag Generator for Notes

Enrich your notes with relevant, AI-suggested tags.

### Usage

```bash
python3 ./auto_tag_generation.py
```

Optional flags:

| Flag        | Description                               |
| ----------- | ----------------------------------------- |
| `--dry-run` | Preview changes, no files modified        |
| `--force`   | Overwrite all existing tags with new ones |

Edit `tag_generation.py`:

```python
VAULT_PATH = "/path/to/your/obsidian/vault"
USE_MODEL = "openai"  # or "gemini" or "ollama"
```

âœ… Tags are inserted in YAML frontmatter â€” ideal for Obsidian users.

---

## ğŸ–¥ï¸ Ollama Local LLM (Optional)

Prefer privacy or offline capabilities? Run fully local models with [Ollama](https://ollama.com/).

### Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

For Linux/macOS or check latest guides on [ollama.com](https://ollama.com/).

### Pull Models

Examples:

```bash
ollama run mistral
ollama run llama3
```

Edit:

```python
USE_MODEL = "ollama"
OLLAMA_MODEL = "mistral"
```

Supports lightweight, privacy-friendly models locally.

---

## ğŸŒŸ Future Plans

- Full-featured Obsidian Plugin (Separate project)
- Persistent chat mode to refine questions without losing context
- Scalable search for large vaults
- More advanced tag generation modes
- CLI improvements and advanced filters

---

## ğŸ“¢ Contributing

Open to contributions â€” PRs, issues, suggestions welcome!

---

## ğŸ“œ License

MIT License â€” Free to use, modify, and distribute.

---

## ğŸ¤– Acknowledgments

- OpenAI
- Google Gemini
- Ollama
- Inspired by Obsidian Copilot

---

## âœ¨ Stay in Control of Your Knowledge â€” Search Smarter
